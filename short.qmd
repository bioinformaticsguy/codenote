---
title: "Short Read"
---
# Short Read Pipeline Documentation
This page serves as a comprehensive guide to the Short Read Pipeline. It tracks the versions of the pipeline used throughout the analysis, along with the exact terminal commands executed to run each step of the pipeline. By documenting both the pipeline versions and the commands, this page ensures reproducibility and transparency in the analysis workflow. Each section includes:

- Pipeline Version: The version of the pipeline that was utilized for the analysis.

- Terminal Commands: A detailed log of all commands executed in the terminal to run the pipeline.

- Execution Details: Descriptions of key steps involved, including any specific parameters or configurations used.

# Setting up the Environment
Below are the one time commands that are needed to setup the env.
```bash
conda create -n nf
conda activate nf
conda install bioconda::nextflow
conda install conda-forge::singularity
cd work/
mkdir raredisease/
cd raredisease/
mkdir workdir outdir
```

# Verify the instalations

Check Nextflow verison 
```bash
(nf)$ nextflow -version

      N E X T F L O W
      version 24.10.6 build 5937
      created 23-04-2025 16:53 UTC (18:53 CEST)
      cite doi:10.1038/nbt.3820
      http://nextflow.io
```

Check Singularity verison 
```bash
(nf)$ singularity -version
singularity version 3.8.6
```

# Run Command
```bash
nextflow run nf-core/raredisease -revision dev -profile bih,test --outdir /data/cephfs-1/home/users/alhassa_m/work/raredisease/outdir/2025-02-05_16-59-21/ -work-dir /data/cephfs-1/home/users/alhassa_m/work/raredisease/workdir/
```

Command with custom config file:

```bash
 nextflow run nf-core/raredisease -revision dev -profile test -c custom.config --outdir /data/cephfs-1/home/users/alhassa_m/scratch/001/ -work-dir /data/cephfs-1/home/users/alhassa_m/scratch/workdir/
```

# Why we need dev or master


```bash
(nf) [alhassa_m@hpc-cpu-204 raredisease]$ nextflow run nf-core/raredisease -profile bih,test --outdir /data/cephfs-1/home/users/alhassa_m/work/raredisease/o
utdir/2025-02-05_16-59-21/ -work-dir /data/cephfs-1/home/users/alhassa_m/work/raredisease/workdir/

 N E X T F L O W   ~  version 24.10.6

Project `nf-core/raredisease` is currently stuck on revision: dev -- you need to explicitly specify a revision with the option `-r` in order to use it
```



# May 19th 2025 Monday
Tried to run the pipline again with the same configurations, it ran for the first time with errors and then I started to recieve errors like below:

```code
(nf) [alhassa_m@hpc-cpu-75 scratch]$  nextflow run nf-core/raredisease -revision dev -profile test -c custom.config --outdir /data/cephfs-1/home/users/alhassa_m/scratch/outdir/001/ -work-dir /data/cephfs-1/home/users/alhassa_m/scratch/workdir/
Nextflow 25.04.2 is available - Please consider updating your version to it

 N E X T F L O W   ~  version 24.10.6

Pulling nf-core/raredisease ...
Disk quota exceeded
(nf) [alhassa_m@hpc-cpu-75 scratch]$
```


Also noted that whenever I run the nextflow pipline it creates the .nextflow.log folder in the scratch folder and in the parent directory as well. 
Currently the problem is that the home directory gets filled up and then there is no space to download the images. 
Once I deleted the .singularity folder in the home directory.
Running the pipeline agian works but it then stops soon because of space error. 

Updated the custom Config File and apparently the file is being used as we can see changes on the terminal:

```code
Institutional config options
  config_profile_name            : Test profile
  config_profile_description     : Custom Config
  config_profile_contact         : Ali Hassan (Institut fuer Humangenetik)
  config_profile_url             : N/A
```

## Current Config File

```python
params {
    config_profile_description = 'Custom Config'
    config_profile_contact     = 'Ali Hassan (Institut fuer Humangenetik)'
    config_profile_url         = 'N/A'
}

params {
    max_memory = 760.GB
    max_cpus   = 48
    max_time   = 72.h
}

process {
    resourceLimits = [
        memory: 760.GB,
        cpus: 48,
        time: 72.h
    ]
    executor = 'slurm'
    scratch  = '$SCRATCHO'
}

singularity {
    enabled = true
}

```


## Next Steps
1. Try to change the project folder in the nextflow run command or in config (projectDir).

```bash
Core Nextflow options
  revision                       : dev
  runName                        : pedantic_bernard
  containerEngine                : singularity
  launchDir                      : /data/cephfs-1/scratch/groups/kircher/users/alhassa_m
  workDir                        : /data/cephfs-1/home/users/alhassa_m/scratch/workdir
  projectDir                     : /data/cephfs-1/home/users/alhassa_m/.nextflow/assets/nf-core/raredisease
  userName                       : alhassa_m
  profile                        : test
  configFiles                    : /data/cephfs-1/home/users/alhassa_m/.nextflow/assets/nf-core/raredisease/nextflow.config, /data/cephfs-1/scratch/groups/kircher/users/alhassa_m/custom.config
```

# May 20th 2025 Tuesday
We haven't changed the project folder rather we have created simlinks for .singularity folder.

```code
ln -s work/.singularity/ .singularity
```


This lets the folder in the home directory but all the real data that takes the space is now in the work directory which has a lot of quotoa.

Finally the pipline finished Running
```python 
-[nf-core/raredisease] Pipeline completed successfully-
Completed at: 20-May-2025 15:48:30
Duration    : 56m 2s
CPU hours   : 11.2
Succeeded   : 1'004
```

The config file is also changed and the current version of the config file looks like this:

```python
workDir = '/data/cephfs-1/work/groups/kircher/users/alhassa_m/run_nf/workdir/'

params {
    config_profile_description = 'Custom Config'
    config_profile_contact     = 'Ali Hassan (Institut fuer Humangenetik)'
    config_profile_url         = 'N/A'
}

params {
    max_memory = 760.GB
    max_cpus   = 48
    max_time   = 72.h
}

process {
    resourceLimits = [
        memory: 760.GB,
        cpus: 48,
        time: 72.h
    ]
    executor = 'slurm'
    scratch  = '/data/cephfs-1/scratch/groups/kircher/users/alhassa_m/'
}

singularity {
    enabled = true
    cacheDir = '/data/cephfs-1/work/groups/kircher/users/alhassa_m/run_nf/workdir/singularity/'
}
```

Current run command is like this: 

```code
nextflow run nf-core/raredisease -revision dev -profile test -c custom.config --outdir /data/cephfs-1/scratch/groups/kircher/users/alhassa_m/outdir/
```

# May 22nd 2025 Thursday
Created a one liner to check which samples are one file each forword and reverse read.

Here is the one liner code:

```code 
search_dir="/data/cephfs-2/unmirrored/groups/kircher/SexDiversity"; prefix="DNA_"; digit_list=({01..49}); for digit in "${digit_list[@]}"; do pattern="*${prefix}${digit}*"; label="${prefix}${digit}"; count=$(find "$search_dir" -name "$pattern" | wc -l); if [ "$count" -eq 4 ]; then echo "$label"; fi; done
```

## Step-by-step explanation of the script

| Step  | Code snippet                                                          | What it does                                                          |
|-------|----------------------------------------------                         |-----------------------------------------------------------            |
| 1     | `search_dir="/data/cephfs-2/unmirrored/groups/kircher/SexDiversity"`  | Defines the directory to search files in.                             |
| 2     | `prefix="DNA_"`                                                       | Sets the prefix part of your file name pattern.                       |
| 3     | `digit_list=({01..49})`                                               | Creates a list/array of zero-padded numbers from 01 to 49.            |
| 4     | `for digit in "${digit_list[@]}"; do`                                 | Starts a loop over each digit in the list.                            |
| 5     | `pattern="*${prefix}${digit}*"`                                       | Builds a file search pattern like `*DNA_01*`, `*DNA_02*`, etc.        |
| 6     | `label="${prefix}${digit}"`                                           | Creates the label to print if the condition matches (e.g., `DNA_01`). |
| 7     | `count=$(find "$search_dir" -name "$pattern" \| wc -l)`               | Counts how many files in `$search_dir` match the pattern.             |
| 8     | `if [ "$count" -eq 4 ]; then echo "$label"; fi`                       | If count equals 4, prints the label.                                  |
| 9     | `done`                                                                | Ends the loop.                                                        |


### Notes:

- The `${prefix}${digit}` construct dynamically builds file name patterns.
- The `find` command searches files recursively in the specified directory.
- `wc -l` counts the number of matching files.
- The `if` condition can be changed to other numeric comparisons like `-gt`, `-ge`, etc.

## Sample Details
After checking this we found that following 8 samples have just ```one``` file per forword/reverse read:

```python
DNA_01
DNA_10
DNA_11
DNA_13
DNA_15
DNA_17
DNA_38
DNA_46
```

After checking this we found that following 30 samples have ```three``` files per forword/reverse read:

```python
DNA_02
DNA_03
DNA_04
DNA_05
DNA_06
DNA_09
DNA_14
DNA_16
DNA_18
DNA_19
DNA_20
DNA_22
DNA_23
DNA_24
DNA_26
DNA_27
DNA_28
DNA_29
DNA_30
DNA_31
DNA_32
DNA_35
DNA_36
DNA_37
DNA_39
DNA_44
DNA_45
DNA_47
DNA_48
DNA_49
```

After checking this we found that following 10 samples have ```three``` files per forword/reverse read:

```python
DNA_07
DNA_08
DNA_21
DNA_25
DNA_33
DNA_34
DNA_40
DNA_41
DNA_42
DNA_43
```

# May 28th 2025 Wednesday

```code 
 nextflow run nf-core/raredisease -revision dev -profile test,singularity -params-file params.yaml -c custom.config    
```

So this time I ran the pipline with just 8GB memory and just 1 core with the command mentioned above. 

Though I have changed the work directory as well as the out directory as previously home work folder got full and my pipline was struck in the middle.


# May 30th 2025 Wednesday
Since the pipline failed, [See Error Here](files/error.log){target="_blank"}:






That I ran last time so I am running this again on the small sample sheet. The difference is that the data is very small and it is the test data from the rare disease pipline.

| sample          | lane | fastq_1                                                                                                                         | fastq_2                                                                                                                         | sex | phenotype | paternal_id | maternal_id | case_id  |
|-----------------|------|----------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------|-----|-----------|-------------|-------------|----------|
| hugelymodelbat  | 1    | /data/cephfs-2/unmirrored/groups/kircher/users/alhassa_m/rare_data/1_171015_HHT5NDSXX_hugelymodelbat_XXXXXX_1.fastq.gz | /data/cephfs-2/unmirrored/groups/kircher/users/alhassa_m/rare_data/1_171015_HHT5NDSXX_hugelymodelbat_XXXXXX_2.fastq.gz | 1   | 2         | 0           | 0           | justhusky |


```code
sample,lane,fastq_1,fastq_2,sex,phenotype,paternal_id,maternal_id,case_id
hugelymodelbat,1,/data/cephfs-2/unmirrored/groups/kircher/users/alhassa_m/rare_data/1_171015_HHT5NDSXX_hugelymodelbat_XXXXXX_1.fastq.gz,/data/cephfs-2/unmirrored/groups/kircher/users/alhassa_m/rare_data/1_171015_HHT5NDSXX_hugelymodelbat_XXXXXX_2.fastq.gz,1,2,0,0,justhusky
```

## Two Reasons for the Error:
1. I was adding singulatity as a profile in the run command. 
2. Then I also noticed that there was genome GRCH38 mentioned in the prams file. 

## Solution
- so first I removed the run command. 
- then I also removed the genome from the prams file. 

## Update
So far I have been able to run the pipeline successfully with the data from the raredisease pipline. I just used 2 files which were given on the github page in the signleton sample sheet. 


```python 
-[nf-core/raredisease] Pipeline completed successfully-
Completed at: 30-May-2025 16:49:16
Duration    : 20m 5s
CPU hours   : 3.6
Succeeded   : 506
```

Next I am gonna run the pipline with my data using the updated prams file.

current params file:

```code
input: "/data/cephfs-1/work/groups/kircher/users/alhassa_m/run_nf/samplesheet_small_single.csv"
outdir: "/data/cephfs-1/scratch/groups/kircher/users/alhassa_m/data_out_nf/outdir/004_sfb_data_no_genome_prams"
```

run command is as follows:

```python
nextflow run nf-core/raredisease -revision dev -profile test -params-file params.yaml -c custom.config
```

# June 3rd 2025 Tuesday
I checked the running jobs and found out the following:

```python
JobID      CPUs   Nodes   Memory(GB) NodeList        RunTime    TimeLimit    JobName
16665798   1      1       8          hpc-cpu-82      23:16:19   7-00:00:00   bash
16682580   6      1       36         hpc-cpu-14      04:18:00   08:00:00     nf-NFCORE_RAREDISEASE_RAREDISEASE_CALL_STRUCTURAL_VARIANTS_CALL_SV_TIDDIT_TIDDIT_SV_(DNA_02)
16682500   6      1       36         hpc-cpu-10      04:28:45   08:00:00     nf-NFCORE_RAREDISEASE_RAREDISEASE_QC_BAM_QUALIMAP_BAMQC_(DNA_02)
```

Script used for this is as below:

```bash


# Print table header
printf "%-10s %-6s %-7s %-10s %-15s %-10s %-12s %-20s\n" \
    "JobID" "CPUs" "Nodes" "Memory(GB)" "NodeList" "RunTime" "TimeLimit" "JobName"

# Loop through all your jobs
for job in $(squeue --user $USER --noheader --format="%i"); do
    scontrol show job "$job" | awk -v jobid="$job" '
    BEGIN {
        name="NA"; cpus="NA"; nodes="NA"; mem="NA";
        nodelist="NA"; runtime="NA"; timelimit="NA";
    }
    /JobName=/ {
        for (i=1;i<=NF;i++) {
            if ($i ~ /^JobName=/) name=substr($i,9);
        }
    }
    /NumCPUs=/ {
        for (i=1;i<=NF;i++) {
            if ($i ~ /^NumCPUs=/) cpus=substr($i,9);
            if ($i ~ /^NumNodes=/) nodes=substr($i,10);
        }
    }
    /TRES=/ {
        match($0, /mem=([0-9]+)([MG]?)B?/, m);
        if (m[1] != "") {
            if (m[2] == "G") mem = m[1];
            else if (m[2] == "M") mem = sprintf("%.1f", m[1]/1024);
            else mem = "NA";
        }
    }
    /NodeList=/ {
        for (i=1;i<=NF;i++) {
            if ($i ~ /^NodeList=/) nodelist=substr($i,10);
        }
    }
    /RunTime=/ {
        for (i=1;i<=NF;i++) {
            if ($i ~ /^RunTime=/) runtime=substr($i,9);
            if ($i ~ /^TimeLimit=/) timelimit=substr($i,11);
        }
    }
    END {
        printf "%-10s %-6s %-7s %-10s %-15s %-10s %-12s %-20s\n", \
               jobid, cpus, nodes, mem, nodelist, runtime, timelimit, name;
    }'
done
```



# June 4rd 2025 Wednesday


Last tome pipeline was struck at:  ```149 more processes waiting for task...``` so then I ran it again. 

Ran the pipeline and nf core spawns a lot of jobs intitially.

```code
[alhassa_m@hpc-login-1 ~]$ date +"%Y-%m-%d %H:%M:%S"
2025-06-04 10:46:05
[alhassa_m@hpc-login-1 ~]$ ./work/sh_scripts/specs_usage.sh
JobID      CPUs   Nodes   Memory(GB) NodeList        RunTime    TimeLimit    JobName
16695642   2      1       16         hpc-cpu-60      00:02:58   7-00:00:00   bash
16695689   6      1       36         hpc-cpu-6       00:01:11   08:00:00     nf-NFCORE_RAREDISEASE_RAREDISEASE_FASTQC_(DNA_02_LNUMBER1)
16695690   6      1       36         hpc-cpu-90      00:01:11   08:00:00     nf-NFCORE_RAREDISEASE_RAREDISEASE_FASTQC_(DNA_02_LNUMBER2)
16695691   6      1       36         hpc-cpu-141     00:01:11   08:00:00     nf-NFCORE_RAREDISEASE_RAREDISEASE_ALIGN_FASTP_(DNA_02_LNUMBER2)
16695693   6      1       36         hpc-cpu-152     00:01:11   08:00:00     nf-NFCORE_RAREDISEASE_RAREDISEASE_ALIGN_FASTP_(DNA_02_LNUMBER1)
16695694   6      1       36         hpc-cpu-153     00:01:11   08:00:00     nf-NFCORE_RAREDISEASE_RAREDISEASE_FASTQC_(DNA_02_LNUMBER3)
16695695   6      1       36         hpc-cpu-95      00:01:11   08:00:00     nf-NFCORE_RAREDISEASE_RAREDISEASE_ALIGN_FASTP_(DNA_02_LNUMBER3)
16695701   1      1       6          hpc-cpu-153     00:01:11   04:00:00     nf-NFCORE_RAREDISEASE_RAREDISEASE_PREPARE_REFERENCES_BWA_INDEX_GENOME_(reference.fasta)
```


# June 10th 2025 Tuesday
Today the pipeline finished in 25 minutes with the test data. 

command to see the rows of both files as in one line
```code
(head -n 1 samplesheet_single.csv && tail -n +2 samplesheet_single.csv && tail -n +2 sssheet.csv) | column -s, -t | less -S
```

checked the sample sheet for both samples and found out that those are same except for the change in the names of the files.

```code
sample          lane  fastq_1                                                                                                                                fastq_2                                                                                                                                sex  phenotype  paternal_id  maternal_id  case_id
dna_01          1     /data/cephfs-2/unmirrored/groups/kircher/SexDiversity/250130_LH00253_0200_A22JF7LLT4_A4842_FASTQ/A4842_DNA_01_S1_L001_R1_001.fastq.gz  /data/cephfs-2/unmirrored/groups/kircher/SexDiversity/250130_LH00253_0200_A22JF7LLT4_A4842_FASTQ/A4842_DNA_01_S1_L001_R2_001.fastq.gz  1    2          0            0            dnafirst
hugelymodelbat  1     /data/cephfs-2/unmirrored/groups/kircher/users/alhassa_m/rare_data/1_171015_HHT5NDSXX_hugelymodelbat_XXXXXX_1.fastq.gz                 /data/cephfs-2/unmirrored/groups/kircher/users/alhassa_m/rare_data/1_171015_HHT5NDSXX_hugelymodelbat_XXXXXX_2.fastq.gz                 1    2          0            0            justhusky
```

Param file is as below:

```code
(nf) [alhassa_m@hpc-cpu-1 run_nf]$ less params.yaml
input: "/data/cephfs-1/work/groups/kircher/users/alhassa_m/run_nf/samplesheet_single.csv"
outdir: "/data/cephfs-1/scratch/groups/kircher/users/alhassa_m/data_out_nf/outdir/008_one_bih_DNA01"
```

sample sheet used below:

```code
(nf) [alhassa_m@hpc-cpu-1 run_nf]$ less samplesheet_single.csv
sample,lane,fastq_1,fastq_2,sex,phenotype,paternal_id,maternal_id,case_id
dna_01,1,/data/cephfs-2/unmirrored/groups/kircher/SexDiversity/250130_LH00253_0200_A22JF7LLT4_A4842_FASTQ/A4842_DNA_01_S1_L001_R1_001.fastq.gz,/data/cephfs-2/unmirrored/groups/kircher/SexDiversity/250130_LH00253_0200_A22JF7LLT4_A4842_FASTQ/A4842_DNA_01_S1_L001_R2_001.fastq.gz,1,2,0,0,dnafirst
```

Date and Time
```code
(nf) [alhassa_m@hpc-cpu-1 run_nf]$ date
Tue Jun 10 21:23:18 CEST 2025
```

Command
```code 
nextflow run nf-core/raredisease -revision dev -profile test -params-file params.yaml -c custom.config
```


It spawned a lot of jobs initially

```code
[alhassa_m@hpc-login-1 ~]$ /data/cephfs-1/home/users/alhassa_m/work/sh_scripts/specs_usage.sh
JobID      CPUs   Nodes   Memory(GB) NodeList        RunTime    TimeLimit    JobName
16742670   1      1       16         hpc-cpu-1       00:10:55   7-00:00:00   bash
16742699   6      1       36                         00:00:00   08:00:00     nf-NFCORE_RAREDISEASE_RAREDISEASE_PREPARE_REFERENCES_GATK_SD_MT_(reference_mt.fa)
16742682   6      1       36         hpc-cpu-113     00:00:03   08:00:00     nf-NFCORE_RAREDISEASE_RAREDISEASE_ALIGN_FASTP_(dna_01_LNUMBER1)
16742683   6      1       36         hpc-cpu-3       00:00:03   08:00:00     nf-NFCORE_RAREDISEASE_RAREDISEASE_FASTQC_(dna_01_LNUMBER1)
16742690   6      1       36         hpc-cpu-59      00:00:03   08:00:00     nf-NFCORE_RAREDISEASE_RAREDISEASE_PREPARE_REFERENCES_GATK_SD_(reference.fasta)
16742701   1      1       6                          00:00:00   04:00:00     nf-NFCORE_RAREDISEASE_RAREDISEASE_PREPARE_REFERENCES_SAMTOOLS_FAIDX_MT_(reference_mt.fa)
16742700   1      1       6                          00:00:00   04:00:00     nf-NFCORE_RAREDISEASE_RAREDISEASE_PREPARE_REFERENCES_BWAMEM2_INDEX_MT_(reference_mt.fa)
16742698   1      1       6                          00:00:00   04:00:00     nf-NFCORE_RAREDISEASE_RAREDISEASE_PREPARE_REFERENCES_TABIX_BGZIPINDEX_PADDED_BED_(target)
16742697   1      1       6                          00:00:00   04:00:00     nf-NFCORE_RAREDISEASE_RAREDISEASE_CALL_SNV_CALL_SNV_DEEPVARIANT_ADD_VARCALLER_TO_BED_(deepvariant)
16742696   1      1       6                          00:00:00   04:00:00     nf-NFCORE_RAREDISEASE_RAREDISEASE_CALL_SNV_POSTPROCESS_MT_CALLS_ADD_VARCALLER_TO_BED_(mutect2)
16742684   1      1       6          hpc-cpu-219     00:00:03   04:00:00     nf-NFCORE_RAREDISEASE_RAREDISEASE_CREATE_HGNCIDS_FILE_(standard)
16742685   1      1       6          hpc-cpu-219     00:00:03   04:00:00     nf-NFCORE_RAREDISEASE_RAREDISEASE_PREPARE_REFERENCES_TABIX_PBT_(target)
16742688   1      1       6          hpc-cpu-13      00:00:03   04:00:00     nf-NFCORE_RAREDISEASE_RAREDISEASE_PREPARE_REFERENCES_BWA_INDEX_GENOME_(reference.fasta)
16742689   1      1       6          hpc-cpu-13      00:00:03   04:00:00     nf-NFCORE_RAREDISEASE_RAREDISEASE_PREPARE_REFERENCES_BWAMEM2_INDEX_GENOME_(reference.fasta)
```


# 12th June 2025

```code
rsync test.config bihlogin1:/data/cephfs-1/home/users/alhassa_m/work/run_nf/

nextflow run nf-core/raredisease -revision dev -profile test -params-file params.yaml -ansi-log false > nextflow_2025.06.12.out
```


# 24th June 2025

So there was some problem with running the pipeline and the was wrror porring up to the peddy as i accidently deleted the nextflow config file. 
I have created the git hub repo with the current release it is able to finish the pipeline with the following command the files can be found in the repo.

[rare-disease-pipeline v1.0.0-beta release](https://github.com/bioinformaticsguy/rare-disease-pipeline/releases/tag/v1.0.0-beta)

```code
nextflow run nf-core/raredisease -revision dev -profile test -c custom.config --outdir /data/cephfs1/scratch/groups/kircher/users/alhassa_m/outdir/ -resume        
```

## Command used for custom config

```code
 nextflow run nf-core/raredisease -revision dev  -c custom.config --outdir /data/cephfs-1/scratch/groups/kircher/users/alhassa_m/outdir/ -params-file params.yaml --skip_tools gens,germlinecnvcaller 

```

last command that I was trying:


```code
nextflow run nf-core/raredisease -revision dev  -c custom.config --outdir /data/cephfs-1/scratch/groups/kircher/users/alhassa_m/outdir/ -params-file params.yaml --skip_tools gens,germlinecnvcaller --skip_workflows mt_annotation,mt_subsample -resume 
```

So I ran it with 2.5.0 -revision and it got struck at 15 more steps and then I came back after lunch and restarted it with resule and it finished in 3 minutes.

## Anomly in the pipeline
I was running the nf-core/raredisease pipeline on a small test dataset with the latest release 2.5.0 (which had previously completed successfully). However, this time the run was taking much longer than expected. Even after a long wait, no new jobs were being spawned by Nextflow, and there was no visible progress. I became skeptical that the pipeline might be stuck.

I eventually terminated the run and restarted it using the -resume flag. Surprisingly, the pipeline then completed in just 3 minutes.

This is quite strange. Initially, I thought this behavior might be related to the BIH cluster environment (e.g. resource issues, scheduler problems), but since it also happens with very small test data, I’m not sure if this is a Nextflow issue or something cluster-specific.

For context, I experienced a similar situation earlier while running the pipeline on real data (~75GB input), where I assumed at the time that it was due to insufficient resources in the config file — but now I suspect there might be more to it.

```python
nextflow run nf-core/raredisease -revision 2.5.0 -profile test -c custom.config --outdir /data/cephfs-1/scratch/groups/kircher/users/alhassa_m/outdir/ -resume


-[nf-core/raredisease] Pipeline completed successfully-
Completed at: 24-Jun-2025 16:31:30
Duration    : 3m 21s
CPU hours   : 7.5 (99.7% cached)
Succeeded   : 7
Cached      : 995
```




## Currently missing files
when using the following command:


```
 nextflow run nf-core/raredisease -revision 2.5.0 -c custom.config -params-file params.yaml --outdir /data/cephfs-1/scratch/groups/kircher/users/alhassa_m/outdir/
```


### Need to generate correct files for grch38
```python
intervals_wgs
intervals_y
```

### These are present in the test profile but test profile is not for grch38
```python
params.svdb_query_dbs should be set.
params.vep_filters
params.variant_catalog not set.
params.vcfanno_resources not set.
params.vcfanno_toml not set.
params.vep_cache not set.
params.gnomad_af not set.
params.score_config_snv not set.
params.variant_consequences_snv not set.
params.score_config_sv not set.
params.variant_consequences_sv not set.
params.mobile_element_references not set.
params.mobile_element_svdb_annotations not set.
```

### Resolved by using skip_germlinecnvcaller = true in the config file

```python
params.ploidy_model not set.
params.gcnvcaller_model not set.
params.readcount_intervals not set.
```

I am also testing it just by using test profile and minimal options in the runn command
to use it in future to show that pipeline runs fine without errors at certain points

Here is the command and I will update if it successfuly finished or not tomorrow:

```python
nextflow run nf-core/raredisease -revision 2.5.0 -profile test -c minimal.config --outdir /data/cephfs-1/scratch/groups/kircher/users/alhassa_m/outdir/ 
```
